# TPMS Dataset Quick Start Guide

ã“ã®ç°¡å˜ãªã‚¬ã‚¤ãƒ‰ã§ã€5åˆ†ä»¥å†…ã«TPMSãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ã„å§‹ã‚ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚

## ğŸš€ ã™ãã«å§‹ã‚ã‚‹

### Step 1: ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª
```python
import pandas as pd

# å°ã•ãªã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
sample_data = pd.read_csv("data/sample_data/sample_features_small.csv")
print(f"Sample data shape: {sample_data.shape}")
print(sample_data.head())
```

### Step 2: ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼ˆãƒ•ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼‰
```bash
# å®Œå…¨ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”Ÿæˆ
cd your-repo-directory
python data/generate_sample_data.py
```

### Step 3: ãƒ‡ãƒ¼ã‚¿åˆ†æã®å®Ÿè¡Œ
```bash
# ãƒ‡ãƒ¼ã‚¿åˆ†æãƒ‡ãƒ¢ã‚’å®Ÿè¡Œ
python examples/data_analysis_demo.py
```

## ğŸ“Š ã™ãä½¿ãˆã‚‹ã‚³ãƒ¼ãƒ‰ä¾‹

### åŸºæœ¬çš„ãªãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
```python
import pandas as pd
import numpy as np

# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
train_data = pd.read_csv("data/sample_data/train_features.csv")
test_data = pd.read_csv("data/sample_data/test_features.csv")

print(f"Training samples: {len(train_data)}")
print(f"Test samples: {len(test_data)}")
print(f"Features: {len(train_data.columns) - 7}")  # Exclude metadata columns
```

### ç‰¹å¾´é‡ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®åˆ†é›¢
```python
# ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿åˆ—ã‚’é™¤å¤–
metadata_cols = ['scenario', 'pressure_condition', 'severity', 
                'actual_pressure_fl', 'actual_pressure_fr', 
                'actual_pressure_rl', 'actual_pressure_rr']

feature_cols = [col for col in train_data.columns if col not in metadata_cols]

# ç‰¹å¾´é‡ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ
X_train = train_data[feature_cols]
y_train = train_data[['actual_pressure_fl', 'actual_pressure_fr', 
                     'actual_pressure_rl', 'actual_pressure_rr']]

X_test = test_data[feature_cols]
y_test = test_data[['actual_pressure_fl', 'actual_pressure_fr', 
                   'actual_pressure_rl', 'actual_pressure_rr']]

print(f"Feature matrix shape: {X_train.shape}")
print(f"Target matrix shape: {y_train.shape}")
```

### ç°¡å˜ãªæ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«
```python
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error

# ãƒ¢ãƒ‡ãƒ«è¨“ç·´ï¼ˆå‰å·¦è¼ªã®ä¾‹ï¼‰
model = RandomForestRegressor(n_estimators=50, random_state=42)
model.fit(X_train, y_train['actual_pressure_fl'])

# äºˆæ¸¬
y_pred = model.predict(X_test)

# è©•ä¾¡
mae = mean_absolute_error(y_test['actual_pressure_fl'], y_pred)
print(f"Mean Absolute Error: {mae:.3f} bar")
```

### ãƒ‡ãƒ¼ã‚¿å¯è¦–åŒ–
```python
import matplotlib.pyplot as plt
import seaborn as sns

# åœ§åŠ›åˆ†å¸ƒã®ç¢ºèª
plt.figure(figsize=(12, 4))

# æ­£å¸¸ vs ç•°å¸¸ã®åœ§åŠ›åˆ†å¸ƒ
plt.subplot(1, 3, 1)
normal_data = train_data[train_data['severity'] == 0]
abnormal_data = train_data[train_data['severity'] > 0]

plt.hist(normal_data['actual_pressure_fl'], alpha=0.7, label='Normal', bins=20)
plt.hist(abnormal_data['actual_pressure_fl'], alpha=0.7, label='Abnormal', bins=20)
plt.xlabel('FL Pressure (bar)')
plt.ylabel('Frequency')
plt.legend()
plt.title('Pressure Distribution')

# è»Šè¼ªé–“ã®åœ§åŠ›ç›¸é–¢
plt.subplot(1, 3, 2)
pressure_cols = ['actual_pressure_fl', 'actual_pressure_fr', 
                'actual_pressure_rl', 'actual_pressure_rr']
corr_matrix = train_data[pressure_cols].corr()
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)
plt.title('Wheel Pressure Correlation')

# é‡è¦åº¦åˆ†æ
plt.subplot(1, 3, 3)
importance = model.feature_importances_
top_features = sorted(zip(feature_cols, importance), key=lambda x: x[1], reverse=True)[:10]

features, importances = zip(*top_features)
plt.barh(range(len(features)), importances)
plt.yticks(range(len(features)), features)
plt.xlabel('Importance')
plt.title('Top 10 Feature Importance')

plt.tight_layout()
plt.show()
```

## ğŸ¯ å…¸å‹çš„ãªã‚¿ã‚¹ã‚¯

### 1. ç•°å¸¸æ¤œçŸ¥ï¼ˆåˆ†é¡ï¼‰
```python
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report

# åˆ†é¡ç”¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆä½œæˆ
y_class_train = train_data['severity']
y_class_test = test_data['severity']

# åˆ†é¡å™¨è¨“ç·´
classifier = RandomForestClassifier(n_estimators=100, random_state=42)
classifier.fit(X_train, y_class_train)

# äºˆæ¸¬ãƒ»è©•ä¾¡
y_pred_class = classifier.predict(X_test)
print(classification_report(y_class_test, y_pred_class, 
                          target_names=['Normal', 'Low', 'Critical']))
```

### 2. åœ§åŠ›å›å¸°ï¼ˆå›å¸°ï¼‰
```python
# å…¨è¼ªåŒæ™‚å›å¸°
from sklearn.multioutput import MultiOutputRegressor

multi_regressor = MultiOutputRegressor(RandomForestRegressor(n_estimators=100, random_state=42))
multi_regressor.fit(X_train, y_train)

# äºˆæ¸¬
y_pred_multi = multi_regressor.predict(X_test)

# å„è¼ªã®MAE
wheels = ['FL', 'FR', 'RL', 'RR']
for i, wheel in enumerate(wheels):
    mae = mean_absolute_error(y_test.iloc[:, i], y_pred_multi[:, i])
    print(f"{wheel} Wheel MAE: {mae:.3f} bar")
```

### 3. æ™‚ç³»åˆ—åˆ†æ
```python
# ç”Ÿãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã®æ™‚ç³»åˆ—åˆ†æ
raw_data = pd.read_csv("data/sample_data/raw_sensor_data.csv")

# ç‰¹å®šæ¡ä»¶ã®ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
condition_data = raw_data[
    (raw_data['scenario'] == 'city_driving') & 
    (raw_data['pressure_condition'] == 'fl_low')
].head(100)

# æ™‚ç³»åˆ—ãƒ—ãƒ­ãƒƒãƒˆ
plt.figure(figsize=(12, 6))
plt.subplot(2, 1, 1)
plt.plot(condition_data['timestamp'], condition_data['actual_pressure_fl'], label='FL Pressure')
plt.plot(condition_data['timestamp'], condition_data['actual_pressure_fr'], label='FR Pressure')
plt.ylabel('Pressure (bar)')
plt.legend()
plt.title('Tire Pressure Over Time')

plt.subplot(2, 1, 2)
plt.plot(condition_data['timestamp'], condition_data['vehicle_speed'], label='Speed')
plt.xlabel('Time (s)')
plt.ylabel('Speed (km/h)')
plt.legend()
plt.title('Vehicle Speed Over Time')

plt.tight_layout()
plt.show()
```

## ğŸ“ˆ æ€§èƒ½æŒ‡æ¨™

### æœŸå¾…ã•ã‚Œã‚‹æ€§èƒ½
- **åœ§åŠ›æ¨å®šç²¾åº¦**: MAE < 0.1 bar
- **ç•°å¸¸æ¤œçŸ¥ç‡**: > 95% (åœ§åŠ›ä½ä¸‹15%ä»¥ä¸Š)
- **å½é™½æ€§ç‡**: < 5%
- **å¿œç­”æ™‚é–“**: < 1åˆ†ï¼ˆåœ§åŠ›ä½ä¸‹æ¤œå‡ºï¼‰

### ãƒ¢ãƒ‡ãƒ«è©•ä¾¡
```python
def evaluate_tpms_performance(y_true, y_pred, threshold=1.8):
    """TPMSæ€§èƒ½è©•ä¾¡"""
    # åœ§åŠ›æ¨å®šç²¾åº¦
    mae = mean_absolute_error(y_true, y_pred)
    
    # ç•°å¸¸æ¤œçŸ¥æ€§èƒ½
    true_anomaly = y_true < threshold
    pred_anomaly = y_pred < threshold
    
    tp = np.sum(true_anomaly & pred_anomaly)
    fp = np.sum(~true_anomaly & pred_anomaly)
    tn = np.sum(~true_anomaly & ~pred_anomaly)
    fn = np.sum(true_anomaly & ~pred_anomaly)
    
    precision = tp / (tp + fp) if (tp + fp) > 0 else 0
    recall = tp / (tp + fn) if (tp + fn) > 0 else 0
    
    return {
        'mae': mae,
        'precision': precision,
        'recall': recall,
        'f1': 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0
    }

# è©•ä¾¡å®Ÿè¡Œ
performance = evaluate_tpms_performance(
    y_test['actual_pressure_fl'].values, 
    y_pred
)
print(f"Performance: {performance}")
```

## ğŸ”§ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ã‚ˆãã‚ã‚‹å•é¡Œ

**1. ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚‰ãªã„**
```bash
# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç”Ÿæˆ
python data/generate_sample_data.py
```

**2. ä¾å­˜é–¢ä¿‚ã‚¨ãƒ©ãƒ¼**
```bash
# å¿…è¦ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install -r requirements.txt
```

**3. ãƒ¡ãƒ¢ãƒªã‚¨ãƒ©ãƒ¼**
```python
# å¤§ããªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å ´åˆã€ãƒãƒ£ãƒ³ã‚¯èª­ã¿è¾¼ã¿
chunk_size = 1000
for chunk in pd.read_csv("large_file.csv", chunksize=chunk_size):
    # Process chunk
    process_chunk(chunk)
```

## ğŸ“š æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

1. **è©³ç´°åˆ†æ**: `examples/data_analysis_demo.py` ã‚’å®Ÿè¡Œ
2. **ã‚«ã‚¹ã‚¿ãƒ ãƒ¢ãƒ‡ãƒ«**: ç‹¬è‡ªã®æ©Ÿæ¢°å­¦ç¿’æ‰‹æ³•ã‚’å®Ÿè£…
3. **å®Ÿãƒ‡ãƒ¼ã‚¿é©ç”¨**: å®Ÿè»Šä¸¡ãƒ‡ãƒ¼ã‚¿ã§ã®æ¤œè¨¼
4. **æ€§èƒ½æœ€é©åŒ–**: ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°

---

**ğŸ‰ ã“ã‚Œã§æº–å‚™å®Œäº†ã§ã™ï¼** ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ã£ã¦TPMSé–‹ç™ºã‚’å§‹ã‚ã¾ã—ã‚‡ã†ã€‚

è³ªå•ã‚„ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãŒã‚ã‚Œã°ã€Issueã§æ°—è»½ã«ãŠèã‹ã›ãã ã•ã„ã€‚